{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e0a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/cnn')\n",
    "\n",
    "from models import ConvNet\n",
    "from preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def read_data(path, **kwargs):\n",
    "    from scipy.interpolate import interp1d\n",
    "    df = pd.read_csv(path, **kwargs)\n",
    "    \n",
    "    # User list comprehension to create a list of lists from Dataframe rows\n",
    "    data_list_of_rows = [list(row) for row in df.values]\n",
    "    \n",
    "    num = int(input(\"input a value between 0 to 3 to choose one signal amongst the 3 signals: \"))\n",
    "    y_axis = data_list_of_rows[num]\n",
    "    \n",
    "    print(\"You have chosen signal:\", num);\n",
    "    \n",
    "    column_in = len(y_axis)\n",
    "    col = range(0,column_in)\n",
    "    x_axis = list(col)\n",
    "    \n",
    "    elon_list = [11, 21, 19, 18, 29]\n",
    "    data_x = np.asarray(x_axis)\n",
    "    data_y = np.asarray(y_axis)\n",
    "\n",
    "    #return data_x, data_y\n",
    "\n",
    "\n",
    "    # Obtain interpolation function (input original x (time) and y (signal))\n",
    "    f = interp1d(data_x, data_y)\n",
    "    # Create new x (same x_min and x_max but different number of data points)\n",
    "    x_new = np.linspace(data_x.min(), data_x.max(), 8192)\n",
    "    # Obtain new y (based on new x)\n",
    "    y_new = f(x_new)\n",
    "    # return both new x and new y\n",
    "    return x_new, y_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f43dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_EXAMPLES = int(1e6)\n",
    "NUM_TEST_EXAMPLES = int(1e4)\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "NUM_WINDOWS = 256\n",
    "INPUT_SIZE = 8192\n",
    "\n",
    "# Define label encoder to decode predictions later on\n",
    "label_encoder = LabelEncoder(NUM_WINDOWS)\n",
    "\n",
    "# Build model (should have the same parameters as the model\n",
    "# in 01_cnn-train.ipynb)\n",
    "model = ConvNet(\n",
    "    filters=[64, 128, 128, 256, 256],\n",
    "    kernel_sizes=[9, 9, 9, 9, 9],\n",
    "    dropout=0.0,\n",
    "    pool_type='max',\n",
    "    pool_sizes=[2, 2, 2, 2, 2],\n",
    "    conv_block_size=1,\n",
    "    input_shape=(INPUT_SIZE, 1),\n",
    "    output_shape=(NUM_WINDOWS, NUM_CLASSES),\n",
    "    residual=False\n",
    ")\n",
    "\n",
    "# Load pretrained weights\n",
    "# If retrained (via 01_train-cnn.ipynb), weights should be loaded as \n",
    "# outputs/weights/weight_{epoch:03d}.h5 (e.g. outputs/weights/weight_009.h5)\n",
    "model.load_weights('output/weights/cnn_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a23b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data (applies linear interpolation to get the right dimension)\n",
    "# t = time; s = signal\n",
    "t, s = read_data('../input/training.csv',header=None, sep=',')\n",
    "\n",
    "# Normalize and add batch dimension (model expect batched data)\n",
    "s_norm = s[None, :, None] / s.max()\n",
    "\n",
    "\n",
    "# Pass to model and make predictions\n",
    "preds = model(s_norm)[0]\n",
    "\n",
    "# .decode will filter out predictions below threshold\n",
    "# and compute the appropriate locations of the peaks\n",
    "probs, locs, areas = label_encoder.decode(preds, threshold=0.5)\n",
    "\n",
    "print(\"Predicted locations:\\n\", locs * t.max())\n",
    "print(\"\\nPredicted areas:\\n\", areas)\n",
    "print(\"\\nPredicted probabilities:\\n\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize locations in the chromatogram\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
    "\n",
    "ax.plot(t, s)\n",
    "\n",
    "for (prob, loc, area) in zip(probs, locs, areas):\n",
    "    y = s.min() - s.max() * 0.05 # location of the triangles\n",
    "    ax.scatter(loc*t.max(), y, color='C1', marker='^', s=100, edgecolors='black')\n",
    "    \n",
    "ax.tick_params(axis='both', labelsize=16)\n",
    "ax.set_ylabel('Signal', fontsize=16)\n",
    "ax.set_xlabel('Time', fontsize=16)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# ax.set_xlim(0.0, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2d8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
